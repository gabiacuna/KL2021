{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "001-Autograd-Tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabiacuna/KL2021/blob/main/Analisis%20de%20Imagenes%20con%20DL/001-Autograd-Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-C2brKaMZSz"
      },
      "source": [
        "**Fecha** : 2021-06-28\n",
        "\n",
        "# Autograd: Diferenciación automática\n",
        "\n",
        "El paquete `autograd` proporciona una diferenciación automática para todas las operaciones\n",
        "en tensores. Es un marco de definición por ejecución, lo que significa que su backprop es\n",
        "definido por cómo se ejecuta su código, y que cada iteración puede ser\n",
        "diferente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5venE7WMZS2"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aBW2mB2MZS4"
      },
      "source": [
        "Creando a un tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCPzARaAMZS5",
        "outputId": "72d9301d-b048-4d64-81d4-57d59b82143a"
      },
      "source": [
        "# Cree un tensor 2x2 con capacidades de acumulación de gradientes\n",
        "x = torch.tensor([[1, 2], [3, 4]], requires_grad=True, dtype=torch.float32)\n",
        "print(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTGuamPlMZS6"
      },
      "source": [
        "Ahora podemos hacer operaciónes sobre los tensores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SXuUYPoMZS7",
        "outputId": "734c8282-2e5c-4984-b716-46eb24ff449c"
      },
      "source": [
        "# Deduct 2 from all elements\n",
        "y = x - 2\n",
        "print(y)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.,  0.],\n",
            "        [ 1.,  2.]], grad_fn=<SubBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzi269xSMZS7"
      },
      "source": [
        "`y` fue creada como resultado de una operación, y por ello tiene ele atributo `grad_fn`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlWcdxU_MZS8",
        "outputId": "4a03ccdd-9ced-4c9a-e6b2-4f2169298b4a"
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<SubBackward0 object at 0x7fe790792350>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRFkh5HPMZS9",
        "outputId": "d8a2a5e9-b7fd-48d5-e681-d8c09df2880f"
      },
      "source": [
        "# ¿Qué pasa acá?\n",
        "print(x.grad_fn)    #Sale none pok x no depende de y, solo tiene requires_grad=True"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RET29EYMZS-",
        "outputId": "789e9e7c-9f92-4935-a2b7-7bd0e479d496"
      },
      "source": [
        "# Let's dig further...\n",
        "y.grad_fn"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SubBackward0 at 0x7fe790797590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxXxOJWBMZS-",
        "outputId": "4778b54d-2edf-44a9-8494-bc4ae53fea38"
      },
      "source": [
        "y.grad_fn.next_functions[0][0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AccumulateGrad at 0x7fe790ca7d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bvcOVDXMZS-",
        "outputId": "613dd2f5-8bdf-4fa2-cf09-b872bf699305"
      },
      "source": [
        "y.grad_fn.next_functions[0][0].variable"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj-jZZTfMZS_",
        "outputId": "81d3da4a-5ebb-4902-d9c5-e0288a08397e"
      },
      "source": [
        "# Podemos aplicar más funciones sobre `y`\n",
        "z = y * y * 3\n",
        "a = z.mean()  # promedio\n",
        "\n",
        "print(z)\n",
        "print(a)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 3.,  0.],\n",
            "        [ 3., 12.]], grad_fn=<MulBackward0>)\n",
            "tensor(4.5000, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arcFMSx4MZS_"
      },
      "source": [
        "## Gradients\n",
        "\n",
        "Ahora podemos retroceder con `out.backward()`, lo cual es equivalente a\n",
        "`out.backward(torch.tensor([1.0]))`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKbjm0s2MZS_"
      },
      "source": [
        "# Backprop\n",
        "a.backward()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jq69UEFMZTA"
      },
      "source": [
        "Print gradients $\\frac{\\text{d}a}{\\text{d}x}$.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adiOqlMzMZTA",
        "outputId": "98981ed5-84fa-4ac8-bbb2-3cb02cfc79ad"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.5000,  0.0000],\n",
            "        [ 1.5000,  3.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wdblDCFMZTA",
        "outputId": "c2358635-6f4b-45c3-dac5-ecaf13cb3245"
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "i = 0\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "    i += 1\n",
        "print(y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1829.9207,  353.0065,  637.1857], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFCPQm9mMZTA",
        "outputId": "297f11f8-a77a-44d9-f3aa-59569ac8567c"
      },
      "source": [
        "# Si no corremos hacia atrás en un escalar, necesitamos especificar el grad_output\n",
        "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
        "y.backward(gradients)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6vfGYLCOSOM"
      },
      "source": [
        "ojito que los `.backward()` se pueden correr solo una vez."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L89hnleiMZTB",
        "outputId": "b222109c-b4f6-4689-aa2b-b5d383485295"
      },
      "source": [
        "print(i)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oIO9CVSMZTB"
      },
      "source": [
        "## Inferencia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buCRtz7UMZTB"
      },
      "source": [
        "# Esta variable decide el rango del tensor por debajo de\n",
        "n = 3"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz7HjOqqO06f",
        "outputId": "4135da45-a3b4-4c04-9d9c-1bcdd6a7750e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x, w, z"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3.], requires_grad=True),\n",
              " tensor([1., 1., 1.], requires_grad=True),\n",
              " tensor(6., grad_fn=<DotBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTFC6U0cMZTB",
        "outputId": "d9703ef0-c80c-42d1-9a9d-50e59aeb4a5d"
      },
      "source": [
        "# Tanto `x` como `w` que permiten la acumulación de gradientes.\n",
        "x = torch.arange(1., n + 1, requires_grad=True)\n",
        "w = torch.ones(n, requires_grad=True)\n",
        "z = w @ x   #Producto punto \n",
        "z.backward()\n",
        "print(x.grad, w.grad, sep='\\n')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1.])\n",
            "tensor([1., 2., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EszKBn1qMZTC",
        "outputId": "9441f56e-0420-47aa-fc01-cdbc034eb261"
      },
      "source": [
        "# Solo `w` que permite la acumulación de gradiente\n",
        "x = torch.arange(1., n + 1)\n",
        "w = torch.ones(n, requires_grad=True)\n",
        "z = w @ x\n",
        "z.backward()\n",
        "print(x.grad, w.grad, sep='\\n')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "tensor([1., 2., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1oO0BowMZTC",
        "outputId": "ffba4539-b14e-4c78-9d5b-384d1055b06e"
      },
      "source": [
        "x = torch.arange(1., n + 1)\n",
        "w = torch.ones(n, requires_grad=True)\n",
        "\n",
        "# Independientemente de lo que haga en este contexto, todos los tensores de la\n",
        "# antorcha no tendrán acumulación de gradiente\n",
        "with torch.no_grad():\n",
        "    z = w @ x\n",
        "\n",
        "try:\n",
        "    z.backward()  # PyTorch arrojará un error aquí, ya que z no tiene acumulaciones graduales.\n",
        "except RuntimeError as e:\n",
        "    print('RuntimeError!!! >:[')\n",
        "    print(e)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RuntimeError!!! >:[\n",
            "element 0 of tensors does not require grad and does not have a grad_fn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZPOAdtZMZTC",
        "outputId": "55b87692-13be-44dd-ed82-3eadd9a8e4be"
      },
      "source": [
        "z"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb_6M3O4MZTD"
      },
      "source": [
        "## More stuff\n",
        "\n",
        "La documentación del paquete de diferenciación automática (`autograd`) se encuentra en\n",
        "http://pytorch.org/docs/autograd."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEQdXLb1MZTD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}